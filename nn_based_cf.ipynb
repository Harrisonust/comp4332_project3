{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Activation, Dense, Flatten, Input, Embedding, Concatenate, Multiply, Dropout, LSTM, Softmax, Bidirectional, LayerNormalization, BatchNormalization, Conv1D, MaxPooling1D, LeakyReLU\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.metrics import RootMeanSquaredError\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import confusion_matrix, classification_report, mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/train.csv')\n",
    "valid_df = pd.read_csv('data/valid.csv')\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "user_df = pd.read_csv('data/user.csv')\n",
    "business_df = pd.read_csv('data/business.csv')\n",
    "\n",
    "user_df.rename(columns={'review_count': 'user_review_count', 'name': 'user_name'}, inplace=True)\n",
    "business_df.rename(columns={'stars': 'business_stars', 'review_count': 'business_review_count', 'name': 'business_name'}, inplace=True)\n",
    "\n",
    "print(train_df.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df[\"stars\"].describe())\n",
    "\n",
    "stars_distribution = train_df[\"stars\"].value_counts().sort_index()\n",
    "\n",
    "plt.title(\"Stars Distribution\")\n",
    "plt.bar(stars_distribution.index, stars_distribution.values)\n",
    "for i in range(len(stars_distribution.index)):\n",
    "    plt.text(i+1, stars_distribution.values[i], str(stars_distribution.values[i]), ha='center', va='bottom', fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the unique users and businesses\n",
    "users = pd.concat([train_df['user_id'], valid_df['user_id'], test_df['user_id']]).unique()\n",
    "businesses = pd.concat([train_df['business_id'], valid_df['business_id'], test_df['business_id']]).unique()\n",
    "\n",
    "# Create user and business dictionaries for mapping to integers\n",
    "user_dict = {user: i for i, user in enumerate(users)}\n",
    "business_dict = {business: i for i, business in enumerate(businesses)}\n",
    "\n",
    "########################## training #############################\n",
    "# Map the users and businesses in the dataframe to integers\n",
    "train_df['user_id_numeric'] = train_df['user_id'].map(user_dict)\n",
    "train_df['business_id_numeric'] = train_df['business_id'].map(business_dict)\n",
    "\n",
    "user_train_X = train_df['user_id_numeric'].values\n",
    "business_train_X = train_df['business_id_numeric'].values\n",
    "train_y = train_df['stars'].values\n",
    "# train_y = keras.utils.to_categorical(train_df['stars'].values-1, num_classes=5)\n",
    "\n",
    "######################## validation #############################\n",
    "valid_df['user_id_numeric'] = valid_df['user_id'].map(user_dict)\n",
    "valid_df['business_id_numeric'] = valid_df['business_id'].map(business_dict)\n",
    "\n",
    "user_valid_X = valid_df['user_id_numeric'].values\n",
    "business_valid_X = valid_df['business_id_numeric'].values\n",
    "valid_y = valid_df['stars'].values\n",
    "# valid_y = keras.utils.to_categorical(valid_df['stars'].values-1, num_classes=5)\n",
    "\n",
    "########################## testing ##############################\n",
    "test_df['user_id_numeric'] = test_df['user_id'].map(user_dict)\n",
    "test_df['business_id_numeric'] = test_df['business_id'].map(business_dict)\n",
    "\n",
    "user_test_X = test_df['user_id_numeric'].values\n",
    "business_test_X = test_df['business_id_numeric'].values\n",
    "test_y = test_df['stars'].values\n",
    "# test_y = keras.utils.to_categorical(test_df['stars'].values-1, num_classes=5)\n",
    "\n",
    "####################### meta_data ###############################\n",
    "# create meta data\n",
    "train_merged_df = train_df.merge(business_df, on='business_id')\n",
    "train_merged_df = train_merged_df.merge(user_df, on='user_id')\n",
    "valid_merged_df = valid_df.merge(business_df, on='business_id')\n",
    "valid_merged_df = valid_merged_df.merge(user_df, on='user_id')\n",
    "test_merged_df = test_df.merge(business_df, on='business_id')\n",
    "test_merged_df = test_merged_df.merge(user_df, on='user_id')\n",
    "\n",
    "features = ['business_stars', 'business_review_count', 'is_open', 'user_review_count', \\\n",
    "            'useful', 'funny', 'cool', 'fans', 'average_stars', 'compliment_hot', 'compliment_more', \\\n",
    "            'compliment_profile', 'compliment_cute', 'compliment_list', 'compliment_note', 'compliment_plain', \\\n",
    "            'compliment_cool', 'compliment_funny', 'compliment_writer', 'compliment_photos']\n",
    "\n",
    "meta_train_X = train_merged_df[features].values\n",
    "meta_valid_X = valid_merged_df[features].values\n",
    "meta_test_X = test_merged_df[features].values\n",
    "\n",
    "# normalize meta data\n",
    "meta_train_X = (meta_train_X - meta_train_X.mean(axis=0)) / meta_train_X.std(axis=0)\n",
    "meta_valid_X = (meta_valid_X - meta_valid_X.mean(axis=0)) / meta_valid_X.std(axis=0)\n",
    "meta_test_X = (meta_test_X - meta_test_X.mean(axis=0)) / meta_test_X.std(axis=0)\n",
    "\n",
    "##############################################################\n",
    "\n",
    "print(f\"user: {len(users)}, business: {len(businesses)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(pred, actual):\n",
    "    # Ignore ratings with value zero.\n",
    "    pred = pred[actual.nonzero()].flatten()\n",
    "    actual = actual[actual.nonzero()].flatten()\n",
    "    return np.sqrt(mean_squared_error(pred, actual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = Input(shape=(1,))\n",
    "business_input = Input(shape=(1,))\n",
    "meta_input = Input(shape=(20))\n",
    "\n",
    "############################### MLP ##################################\n",
    "\n",
    "# MLP Embedding layers for users and business\n",
    "mlp_embedding_dim = 10\n",
    "user_mlp_embedding    = Embedding(input_dim=len(users), output_dim=mlp_embedding_dim)(user_input)\n",
    "busines_mlp_embedding = Embedding(input_dim=len(businesses), output_dim=mlp_embedding_dim)(business_input)\n",
    "\n",
    "# Flatten the embeddings\n",
    "user_mlp_flatten    = Flatten()(user_mlp_embedding)\n",
    "busines_mlp_flatten = Flatten()(busines_mlp_embedding)\n",
    "\n",
    "mlp_concatenated = Concatenate()([user_mlp_flatten, busines_mlp_flatten])\n",
    "\n",
    "# MLP layers\n",
    "hidden_layer = Dense(64, activation='relu')(mlp_concatenated)\n",
    "hidden_layer = Dense(64, activation='relu')(hidden_layer)\n",
    "mlp_vector   = Dense(64, activation='relu')(hidden_layer)\n",
    "\n",
    "############################### MF ###################################\n",
    "\n",
    "# MF Embedding layers for users and business\n",
    "mf_embedding_dim = 10\n",
    "user_mf_embedding    = Embedding(input_dim=len(users), output_dim=mf_embedding_dim)(user_input)\n",
    "busines_mf_embedding = Embedding(input_dim=len(businesses), output_dim=mf_embedding_dim)(business_input)\n",
    "# Flatten the embeddings\n",
    "user_mf_flatten    = Flatten()(user_mf_embedding)\n",
    "busines_mf_flatten = Flatten()(busines_mf_embedding)\n",
    "\n",
    "user_mf_norm    = LayerNormalization()(user_mf_flatten)\n",
    "busines_mf_norm = LayerNormalization()(busines_mf_flatten)\n",
    "\n",
    "mf_vector = Multiply()([user_mf_norm, busines_mf_norm])\n",
    "\n",
    "############################### META ################################\n",
    "meta_norm    = LayerNormalization()(meta_input)\n",
    "hidden_layer = Dense(64, activation='relu')(meta_norm)\n",
    "hidden_layer = Dense(64, activation='relu')(hidden_layer)\n",
    "meta_vector  = Dense(64, activation='relu')(hidden_layer)\n",
    "\n",
    "########################### Concatenate ##############################\n",
    "\n",
    "concatenated = Concatenate()([mf_vector, mlp_vector, meta_vector])\n",
    "output_layer = Dense(1)(concatenated)\n",
    "\n",
    "######################################################################\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=[user_input, business_input, meta_input], outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=[RootMeanSquaredError()])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(patience=10)\n",
    "history = model.fit([user_train_X, business_train_X, meta_train_X], train_y, epochs=1, batch_size=64, \\\n",
    "                    validation_data=([user_valid_X, business_valid_X, meta_valid_X], valid_y), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper right')\n",
    "plt.suptitle('Model training history')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict([user_train_X, business_train_X, meta_train_X])\n",
    "print(\"Train set RMSE: \", rmse(y_pred, train_y))\n",
    "\n",
    "y_pred = model.predict([user_valid_X, business_valid_X, meta_valid_X])\n",
    "print(\"Validation set RMSE: \", rmse(y_pred, valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save prediction to csv\n",
    "valid_df['stars'] = y_pred\n",
    "valid_df.drop([\"user_id_numeric\", \"business_id_numeric\"], axis=1, inplace=True)\n",
    "valid_df.to_csv('data/valid_pred.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict([user_test_X, business_test_X, meta_test_X])\n",
    "test_df['stars'] = y_pred\n",
    "test_df.drop([\"user_id_numeric\", \"business_id_numeric\"], axis=1, inplace=True)\n",
    "test_df.to_csv('data/test_pred.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply pca\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "meta_train_X_pca = pca.fit_transform(meta_train_X)\n",
    "meta_valid_X_pca = pca.transform(meta_valid_X)\n",
    "meta_test_X_pca = pca.transform(meta_test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "plt.scatter(meta_train_X_pca[:, 0], meta_train_X_pca[:, 1], c=train_y, cmap='viridis')\n",
    "plt.xlabel('PCA 1')\n",
    "plt.ylabel('PCA 2')\n",
    "plt.xlim(-2,10)\n",
    "plt.ylim(-7,7)\n",
    "plt.title('PCA on meta data')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp4332",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
